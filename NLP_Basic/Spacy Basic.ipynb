{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21722b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3dddc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9c3f7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u'Tesla is looking at buying U.S. startup for $4 million. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a02c11a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla\n",
      "is\n",
      "looking\n",
      "at\n",
      "buying\n",
      "U.S.\n",
      "startup\n",
      "for\n",
      "$\n",
      "4\n",
      "million\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d800875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla 95\n",
      "is 99\n",
      "looking 99\n",
      "at 84\n",
      "buying 99\n",
      "U.S. 95\n",
      "startup 91\n",
      "for 84\n",
      "$ 98\n",
      "4 92\n",
      "million 92\n",
      ". 96\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd13e94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla PROPN\n",
      "is VERB\n",
      "looking VERB\n",
      "at ADP\n",
      "buying VERB\n",
      "U.S. PROPN\n",
      "startup NOUN\n",
      "for ADP\n",
      "$ SYM\n",
      "4 NUM\n",
      "million NUM\n",
      ". PUNCT\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ec83707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla PROPN nsubj\n",
      "is VERB aux\n",
      "looking VERB ROOT\n",
      "at ADP prep\n",
      "buying VERB pcomp\n",
      "U.S. PROPN compound\n",
      "startup NOUN dobj\n",
      "for ADP prep\n",
      "$ SYM quantmod\n",
      "4 NUM compound\n",
      "million NUM pobj\n",
      ". PUNCT punct\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_) #Syntactic dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0dbffde3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tagger', <spacy.pipeline.Tagger at 0x26f92af6248>),\n",
       " ('parser', <spacy.pipeline.DependencyParser at 0x26f92ad2f48>),\n",
       " ('ner', <spacy.pipeline.EntityRecognizer at 0x26f92af4528>)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e55d3857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tagger', 'parser', 'ner']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7262deb",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "712fb0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = nlp(u\"Tesla isn't lokking into      startups anymore.\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "860a9e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla PROPN nsubj\n",
      "is VERB aux\n",
      "n't ADV neg\n",
      "lokking VERB ROOT\n",
      "into ADP prep\n",
      "      SPACE \n",
      "startups NOUN pobj\n",
      "anymore ADV advmod\n",
      ". PUNCT punct\n"
     ]
    }
   ],
   "source": [
    "for token in doc2:\n",
    "    print(token.text, token.pos_, token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23d89e4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d7fc6cb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'be'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2[1].lemma_  #.text_, .lemma_, .pos_, .tag_, .shape_, .is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9370c53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc3 = nlp(u'Wikipedia was launched on January 15, 2001, by Jimmy Wales[7] and Larry Sanger; Sanger coined its name as a blending of \"wiki\" and \"encyclopedia\".[8][9] Initially available only in English, versions in other languages were quickly developed. Its combined editions comprise more than 57 million articles, attracting around 2 billion unique device visits per month, and more than 17 million edits per month (1.9 edits per second).[10][11] In 2006, Time magazine stated that the policy of allowing anyone to edit had made Wikipedia the \"biggest (and perhaps best) encyclopedia in the world\", and is \"a testament to the vision of one man, Jimmy Wales\".[12]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f2a47ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "quote = doc3[20:32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ffe29edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name as a blending of \"wiki\" and \"encyclopedia\".[8][9]\n"
     ]
    }
   ],
   "source": [
    "print(quote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bc4ee380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.span.Span"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(quote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1a363992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f30e7e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc4 = nlp(u\"This is the first sentences. This is an another sentence. And this is the last sentence.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3add9225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the first sentences.\n",
      "This is an another sentence.\n",
      "And this is the last sentence.\n"
     ]
    }
   ],
   "source": [
    "for sentance in doc4.sents:\n",
    "    print(sentance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8d0a0e8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "This"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc4[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6082b6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc4[6].is"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
